{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pwd",
   "id": "871fb9e155464de9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from Levenshtein import ratio\n",
    "import re\n",
    "\n",
    "\n",
    "# Pattern for CVE identifiers\n",
    "pattern = r\"CVE-\\d{4}-\\d{4,7}\"\n",
    "\n",
    "\n",
    "df_hf = pd.read_csv('./inference/distilbert/hf_disc.csv')\n",
    "df_hf = df_hf.drop_duplicates(subset=[\"full_content\"]).rename(columns={\"full_content\": \"full_content\"})\n",
    "print(len(df_hf))\n",
    "\n",
    "df_ghd = pd.read_csv('./inference/distilbert/gh_disc.csv')\n",
    "df_ghd = df_ghd.drop_duplicates(subset=[\"discussion_title\", \"content\"])\n",
    "df_ghd['discussion_title_content'] = df_ghd['discussion_title'].astype(str) + '\\n' + df_ghd['content'].astype(str)\n",
    "df_ghd = df_ghd.rename(columns={\"discussion_title_content\": \"full_content\"})\n",
    "print(len(df_ghd))\n",
    "\n",
    "df_ghi = pd.read_csv('./inference/distilbert/gh_issues_distilbert_filtered.csv')\n",
    "df_ghi = df_ghi.drop_duplicates(subset=[\"full_comment\"]).rename(columns={\"full_comment\": \"full_content\"})\n",
    "print(len(df_ghi))"
   ],
   "id": "f19ceb65b7f9c4a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_ghd",
   "id": "6ef1635fcbff9e6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2a54d831301ad3d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pattern = r\"CVE-\\d{4}-\\d{4,7}\"\n",
    "\n",
    "all_matches = []\n",
    "count_matches = 0\n",
    "\n",
    "for df in [df_hf, df_ghd, df_ghi]:\n",
    "    matches = df['full_content'].str.findall(r\"CVE-\\d{4}-\\d{4,7}\")\n",
    "    matches = matches[matches.apply(lambda x: len(x) > 0)]\n",
    "    count_matches += matches.shape[0]\n",
    "    all_matches.extend(matches.explode().tolist())\n",
    "print(all_matches)\n",
    "print(\"Number of rows containing CVE patterns:\", count_matches)\n",
    "\n",
    "# print(count_matches)\n",
    "df_cve = pd.DataFrame(all_matches, columns=['cve'])\n",
    "df_cve\n",
    "\n"
   ],
   "id": "abdec878d91f3429",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(len(df_cve))\n",
    "df_cve = df_cve.drop_duplicates()\n",
    "print(len(df_cve))\n",
    "df_cve"
   ],
   "id": "8c69557f4dedff2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "def fetch_cve_record(cve_id):\n",
    "    url = f\"https://cveawg.mitre.org/api/cve/{cve_id}\"\n",
    "    response = None\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=30)\n",
    "        if resp.status_code == 200:\n",
    "            response =  resp.json()\n",
    "        else:\n",
    "            response = None\n",
    "    except Exception as e:\n",
    "        response = None\n",
    "\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "df_cve['cve_record'] = df_cve['cve'].apply(fetch_cve_record)\n",
    "df_cve.to_csv(\n",
    "     './cve.csv',\n",
    "        index=False\n",
    ")"
   ],
   "id": "1f455713219c8bb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fetch_cve_record(cve_id):\n",
    "    print(cve_id)\n",
    "    url = f\"https://services.nvd.nist.gov/rest/json/cves/2.0?cveId={cve_id}\"\n",
    "    response = None\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=30)\n",
    "        if resp.status_code == 200:\n",
    "            response =  resp.json()\n",
    "        else:\n",
    "            response = None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        response = None\n",
    "    print(response)\n",
    "    return response\n"
   ],
   "id": "56b7c5aaa1f0b81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_cve['cve_record_nvd'] = df_cve['cve'].apply(fetch_cve_record)\n",
    "df_cve.to_csv(\n",
    "     './cve.csv',\n",
    "        index=False\n",
    ")"
   ],
   "id": "911c04ab47d74e12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Filter records where cve_record_nvd is None and rerun fetch_cve_record\n",
    "mask = df_cve['cve_record_nvd'].isna()\n",
    "print(len(mask))\n",
    "df_cve.loc[mask, 'cve_record_nvd'] = df_cve.loc[mask, 'cve'].apply(fetch_cve_record)\n",
    "df_cve.to_csv(\n",
    "     './cve.csv',\n",
    "        index=False\n",
    ")"
   ],
   "id": "dcc0849272981b2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_cwe(nvd_cve_record):\n",
    "\n",
    "    cwe = set()\n",
    "    vuls = nvd_cve_record.get('vulnerabilities', [])\n",
    "    for vul in vuls:\n",
    "        cve = vul.get(\"cve\", {})\n",
    "        print(cve[\"id\"])\n",
    "        weaknesses = cve.get(\"weaknesses\")\n",
    "        if not weaknesses:\n",
    "            continue\n",
    "        for weakness in weaknesses:\n",
    "            cwe_desc = weakness.get(\"description\")\n",
    "            if cwe_desc:\n",
    "                for cwe_desc in cwe_desc:\n",
    "                    cwe_id = cwe_desc.get(\"value\")\n",
    "                    if cwe_id:\n",
    "                        cwe.add(cwe_id)\n",
    "        print(vul[\"cve\"][\"id\"], list(cwe))\n",
    "    return list(cwe)\n",
    "\n",
    "def get_cve_status(nvd_cve_record):\n",
    "    status = None\n",
    "    vuls = nvd_cve_record.get('vulnerabilities', [])\n",
    "    for vul in vuls:\n",
    "        cve = vul.get(\"cve\", {})\n",
    "        print(cve[\"id\"])\n",
    "        status = cve.get(\"vulnStatus\")\n",
    "    return status\n",
    "\n",
    "df_cve['cwe'] = df_cve['cve_record_nvd'].apply(get_cwe)\n",
    "df_cve['cve_status'] = df_cve['cve_record_nvd'].apply(get_cve_status)\n",
    "df_cve\n"
   ],
   "id": "2da93a74c796b661",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fetch_cwe_record(cwe_id):\n",
    "    id = cwe_id.replace(\"CWE-\", \"\")\n",
    "    url = f\"https://cwe-api.mitre.org/api/v1/cwe/weakness/{id}\"\n",
    "    result = None\n",
    "    print(url)\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=30,  verify=False)\n",
    "        if resp.status_code == 200:\n",
    "            data = resp.json()\n",
    "            result =  data.get(\"Weaknesses\", [])[0][\"Name\"] if data.get(\"Weaknesses\") else None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = None\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "def get_cwe_names(cwe_list):\n",
    "    if not isinstance(cwe_list, list):\n",
    "        return []\n",
    "    return [fetch_cwe_record(cwe_id) for cwe_id in cwe_list]\n",
    "\n",
    "df_cve['cwe_record'] = df_cve['cwe'].apply(get_cwe_names)\n",
    "df_cve"
   ],
   "id": "8f8549d2b8575bac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2397c34d5c2092ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "\n",
    "def format_ref(nvd_cve_record, cwe_id, cwe_record):\n",
    "    print(cwe_id)\n",
    "    txt = dedent(\n",
    "        \"\"\"\n",
    "        {cve_id}\n",
    "        Description: {description}\n",
    "        Weakness Enumeration: {cwe_id}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    cve_id = \"\"\n",
    "    cve_description = \"\"\n",
    "    vuls = nvd_cve_record.get('vulnerabilities', [])\n",
    "    for vul in vuls:\n",
    "        cve = vul.get(\"cve\", {})\n",
    "        cve_id = cve.get(\"id\", \"\")\n",
    "        cve_description = cve.get(\"descriptions\", [])[0][\"value\"]\n",
    "\n",
    "\n",
    "    cwe_str = \", \".join([f\"{cwei} {cewr}\" for cwei, cewr in zip(list(cwe_id), list(cwe_record))])\n",
    "    print(cwe_str)\n",
    "    return txt.format(cve_id=cve_id, description=cve_description, cwe_id=cwe_str)\n",
    "\n",
    "df_cve['cve_nvd_ref'] = df_cve.apply(lambda row: format_ref(row['cve_record_nvd'], row['cwe'], row['cwe_record']), axis=1)\n",
    "df_cve"
   ],
   "id": "7b0231bd40a49994",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_cve.to_csv(\n",
    "     './cve.csv',\n",
    "    index=False\n",
    ")"
   ],
   "id": "22395397d75586f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_cve",
   "id": "6f4070aae2966454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_cve.loc[mask, 'cve_record_nvd']",
   "id": "5b2acc2fbe3f869d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mapping_model_links = pd.read_csv(\n",
    "    './mapping_models_links.csv')\n",
    "mapping_gh_links = pd.read_csv(\n",
    "    './mapping_repositories_url.csv')\n",
    "print(len(mapping_model_links))\n",
    "print(len(mapping_gh_links))"
   ],
   "id": "3f4873f1d991cfc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grouped = df.groupby('repo_name').agg({\n",
    "    'issue_number': lambda x: list(x),\n",
    "    'issue_number': 'count'\n",
    "}).rename(columns={'issue_number': 'issue_count'})\n",
    "\n",
    "grouped['issues'] = df.groupby('repo_name')['issue_number'].apply(list)\n",
    "grouped['issue_count'] = df.groupby('repo_name')['issue_number'].count()\n",
    "grouped = grouped.reset_index()\n",
    "\n",
    "repo_to_link = dict(zip(mapping_gh_links['repo_name'], mapping_gh_links['github_link']))\n",
    "grouped['github_link'] = grouped['repo_name'].map(repo_to_link)\n",
    "\n",
    "\n",
    "# # Find model_id for each repo_name by checking if github_link is in github_links list\n",
    "def find_model_id(github_link):\n",
    "    for _, row in mapping_model_links.iterrows():\n",
    "        links = [link.strip() for link in row['github_links'].strip('[]').split(',')] if isinstance(row['github_links'],\n",
    "                                                                                                    str) else []\n",
    "        if github_link in links:\n",
    "            return row['model_id']\n",
    "    return None\n",
    "\n",
    "\n",
    "#\n",
    "grouped['model_id'] = grouped['github_link'].apply(find_model_id)\n",
    "# grouped\n",
    "\n",
    "#\n",
    "# # Create project_name\n",
    "grouped['project_name'] = grouped['model_id'].astype(str) + '_' + grouped['repo_name']\n",
    "#\n",
    "# # Reorder columns\n",
    "final_df = grouped[['project_name', 'model_id', 'repo_name', 'github_link', 'issues', 'issue_count']]\n",
    "final_df.head()\n"
   ],
   "id": "4ba30320b349628b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_df",
   "id": "f37c3616834d0c16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "final_df.to_csv(\n",
    "    './mapping_issues.csv',\n",
    "    index=False\n",
    ")"
   ],
   "id": "70d603cb87c4187",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# gh disc\n",
    "df = pd.read_csv('./inference/distilbert/gh_disc.csv')\n",
    "grouped_disc = df.groupby('repo_name').agg({\n",
    "    'discussion_number': lambda x: list(x),\n",
    "    'discussion_number': 'count'\n",
    "}).rename(columns={'discussion_number': 'discussion_count'})\n",
    "\n",
    "grouped_disc['discussions'] = df.groupby('repo_name')['discussion_number'].apply(list)\n",
    "grouped_disc['discussions_count'] = df.groupby('repo_name')['discussion_number'].count()\n",
    "grouped_disc = grouped_disc.reset_index()\n",
    "\n",
    "repo_to_link = dict(zip(mapping_gh_links['repo_name'], mapping_gh_links['github_link']))\n",
    "grouped_disc['github_link'] = grouped_disc['repo_name'].map(repo_to_link)\n",
    "# grouped_disc\n",
    "\n",
    "mapping_model_links[\"links\"] = mapping_model_links[\"github_links\"].apply(\n",
    "    lambda x: [link.strip() for link in x.strip('[]').split(',')] if isinstance(x, str) else []\n",
    ")\n",
    "\n",
    "grouped_disc['model_id'] = grouped_disc['github_link'].apply(\n",
    "    lambda link: next(\n",
    "        (row['model_id'] for _, row in mapping_model_links.iterrows() if link in row['links']),\n",
    "        None\n",
    "    )\n",
    ")\n",
    "\n",
    "grouped_disc\n"
   ],
   "id": "8a5d32ffa042e2a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grouped_disc.to_csv('./mapping_gh.csv',\n",
    "                    index=False)"
   ],
   "id": "ba6e7208189b1c3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# hf disc\n",
    "df = pd.read_csv('./inference/distilbert/hf_disc.csv')\n",
    "grouped_disc = df.groupby('model_id').agg({\n",
    "    'num': lambda x: list(x),\n",
    "    'num': 'count'\n",
    "}).rename(columns={'num': 'discussion_count'})\n",
    "\n",
    "grouped_disc['discussions'] = df.groupby('model_id')['num'].apply(list)\n",
    "grouped_disc['discussions_count'] = df.groupby('model_id')['num'].count()\n",
    "grouped_disc = grouped_disc.reset_index()\n",
    "grouped_disc\n",
    "\n",
    "grouped_disc.to_csv('./mapping_hf.csv',\n",
    "                    index=False)"
   ],
   "id": "c2fb1e5dc01811b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import huggingface_hub\n",
    "hf = pd.read_csv('./mapping_hf.csv')\n",
    "hf"
   ],
   "id": "81a8b6ddece9a555",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hf_api= huggingface_hub.HfApi()\n",
    "def get_pipeline_from_hf(model_id):\n",
    "    pipeline = None\n",
    "    try:\n",
    "        pipeline = hf_api.model_info(model_id).pipeline_tag\n",
    "    except Exception as exc:\n",
    "        print(exc)\n",
    "    return pipeline\n",
    "\n",
    "hf[\"pipeline_tag\"] = hf['model_id'].apply(get_pipeline_from_hf)\n",
    "hf"
   ],
   "id": "9f2edf3a1464b9c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hf = pd.read_csv(\"./model_pipeline_tag.csv\")\n",
    "hf"
   ],
   "id": "4c64d93c079f2ea8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# show the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "model_tags = hf_api.get_model_tags()\n",
    "pipeline_tags = model_tags[\"pipeline_tag\"]\n",
    "subtype = set()\n",
    "for tag in pipeline_tags:\n",
    "    subtype.add(tag[\"subType\"])\n",
    "    # print(tag)\n",
    "print(\"Subtypes:\", subtype)\n",
    "\n",
    "groups = dict.fromkeys(subtype)\n",
    "for tag in pipeline_tags:\n",
    "    if not groups[tag[\"subType\"]]:\n",
    "        groups[tag[\"subType\"]] = []\n",
    "    groups[tag[\"subType\"]].append(tag[\"id\"])\n",
    "print(groups)\n",
    "\n",
    "# Map pipeline_tags to their group based on the 'groups' dictionary\n",
    "def map_tag_to_group(tag):\n",
    "    tag = str(tag).strip().lower().replace(\" \", \"-\")\n",
    "    for group, tags in groups.items():\n",
    "        if tag in tags:\n",
    "            return group\n",
    "    return \"Not Provided\"\n",
    "\n",
    "hf['pipeline_group'] = hf['pipeline_tag'].apply(map_tag_to_group)\n",
    "\n",
    "pipeline_group_counts = hf.groupby('pipeline_group')['model_id'].nunique().reset_index()\n",
    "# pipeline_group_counts_filtered = hf[hf['pipeline_group'] != \"Not Provided\"].groupby('pipeline_group')['model_id'].nunique().reset_index()\n",
    "pipeline_group_counts_filtered = hf.groupby('pipeline_group')['model_id'].nunique().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(\n",
    "    data=pipeline_group_counts_filtered.sort_values('model_id', ascending=False),\n",
    "    x='pipeline_group',\n",
    "    y='model_id',\n",
    ")\n",
    "plt.title('Number of Models by Task Type')\n",
    "plt.xlabel('Task')\n",
    "plt.ylabel('Number of Models')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{int(height)}', (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "plt.show()\n",
    "plt.show()\n",
    "pipeline_group_counts = hf.groupby('pipeline_tag')['model_id'].nunique().reset_index()\n",
    "# pipeline_group_counts = rq_df[rq_df['pipeline_group'] != \"Not Provided\"].groupby('pipeline_group')['model_id'].nunique().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(\n",
    "    data=pipeline_group_counts.sort_values('model_id', ascending=False),\n",
    "    x='pipeline_tag',\n",
    "    y='model_id',\n",
    ")\n",
    "plt.title('Number of Models by Pipeline Tags')\n",
    "plt.xlabel('Pipeline Tags')\n",
    "plt.ylabel('Number of Models')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{int(height)}', (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "plt.show()\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "5ae67fbaf480142b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# Count number of models per (pipeline_group, pipeline_tag)\n",
    "tag_counts = (\n",
    "    hf.groupby(['pipeline_group', 'pipeline_tag'])['model_id']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'model_id': 'model_count'})\n",
    ")\n",
    "\n",
    "# Sort by group then descending count\n",
    "tag_counts = tag_counts.sort_values(['pipeline_group', 'model_count'], ascending=[True, False])\n",
    "# tag_counts= tag_counts.reset_index()\n",
    "tag_counts = tag_counts.set_index([\"pipeline_group\",\"pipeline_tag\"])\n",
    "tag_counts"
   ],
   "id": "caa158962b5eec7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tag_counts.index.get_level_values(level=0)",
   "id": "6b5ca5c1d5f8a8f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,figsize=(20,5))\n",
    "tag_counts.plot(kind='bar', xlabel='', ax=ax)\n",
    "ax.set_xticklabels(tag_counts.index.get_level_values(level=1).tolist(), rotation=90)\n",
    "\n",
    "for container in ax.containers:\n",
    "    for i,child in enumerate(container.get_children()):\n",
    "        if i == 0:\n",
    "            ax.text(child.xy[0]+child.get_width(), -0.5, tag_counts.index.get_level_values(level=0)[0], ha='center', transform=ax.transAxes)\n",
    "        elif i == 2:\n",
    "            ax.text(child.xy[0]-(child.get_width()*2), -0.5, tag_counts.index.get_level_values(level=0)[2], ha='center', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ],
   "id": "663baf38822a77d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tag_counts = (\n",
    "    hf.groupby(['pipeline_group', 'pipeline_tag'])['model_id']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'model_id': 'model_count'})\n",
    ")\n",
    "tag_counts.set_index([\"pipeline_group\",\"pipeline_tag\"])\n",
    "tag_counts"
   ],
   "id": "8734c09a4500a073",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hf",
   "id": "b0cabdc1912aeb2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hf_api= huggingface_hub.HfApi()\n",
    "\n",
    "def get_base_model(row):\n",
    "    base_model_from_card = \"\"\n",
    "    adapter = 0\n",
    "    merge = 0\n",
    "    quantized = 0\n",
    "    finetune = 0\n",
    "    base_or_downstream = \"unknown\"\n",
    "\n",
    "    try:\n",
    "        model_info_expand = hf_api.model_info(\n",
    "            row[\"model_id\"],\n",
    "            expand=[\n",
    "                \"baseModels\",\n",
    "                \"childrenModelCount\",\n",
    "                \"downloadsAllTime\",\n",
    "                \"trendingScore\",\n",
    "                \"cardData\",\n",
    "                \"tags\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        card_data_dict = model_info_expand.card_data.to_dict() if model_info_expand.card_data else None\n",
    "        if card_data_dict:\n",
    "            card_data_dict = {\n",
    "                k: v for k, v in card_data_dict.items()\n",
    "                if not (any(x in k for x in [\"extra_gated\", \"widget\"]))  # remove this to save space\n",
    "            }\n",
    "\n",
    "        # base model can comes from tags or model cards\n",
    "        base_model_from_card = None\n",
    "        if card_data_dict:\n",
    "            base_model_from_card = card_data_dict.get(\"base_model\")\n",
    "\n",
    "        chains = dict(model_info_expand.childrenModelCount)\n",
    "        adapter = chains.get(\"adapter\", 0)\n",
    "        merge = chains.get(\"merge\", 0)\n",
    "        quantized = chains.get(\"quantized\", 0)\n",
    "        finetune = chains.get(\"finetune\", 0)\n",
    "\n",
    "        if base_model_from_card:\n",
    "            base_or_downstream = 'downstream'\n",
    "        else:\n",
    "            if adapter > 0 or merge > 0 or quantized > 0 or finetune > 0:\n",
    "                base_or_downstream = 'base'\n",
    "            else:\n",
    "                base_or_downstream = 'unknown'\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    print(base_model_from_card, adapter, merge, quantized, finetune, base_or_downstream)\n",
    "    return base_model_from_card, adapter, merge, quantized, finetune, base_or_downstream\n",
    "\n",
    "hf[[\"base_model_from_card_data\", \"adapter\", \"merge\", \"quantized\", \"finetune\", \"base_or_downstream\"]] = hf.apply(get_base_model, axis=1, result_type=\"expand\")\n",
    "hf.to_csv(\"./model_base.csv\")\n",
    "hf"
   ],
   "id": "e48e53831ed8f497",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hf",
   "id": "b47c203721852d77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hf[\"base_or_downstream\"].value_counts()",
   "id": "2d4d34337febede3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hf_sec_count = hf[['base_or_downstream',\"discussion_count\"]].groupby('base_or_downstream')[\"discussion_count\"].sum()\n",
    "hf_sec_count"
   ],
   "id": "9f50817b251ae67f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# base_model_pipeline_group_counts = rq_df.groupby('is_base_model')['model_id'].nunique().reset_index()\n",
    "base_model_pipeline_group_counts = hf[hf['base_or_downstream'] != 'unknown'].groupby('base_or_downstream')['model_id'].nunique().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(\n",
    "    data=base_model_pipeline_group_counts.sort_values('base_or_downstream', ascending=False),\n",
    "    x='base_or_downstream',\n",
    "    y='model_id',\n",
    ")\n",
    "plt.title('Number of Models by Model Type')\n",
    "plt.xlabel('Model Type')\n",
    "plt.ylabel('Number of Models')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{int(height)}', (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "plt.show()\n",
    "plt.show()\n"
   ],
   "id": "d7841204417cb4fe",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
